# -*- coding: utf-8 -*-
"""tf-keras-practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FVXPqM4VaLkqFyf4DkFE28OkoBEqaQD6
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Model, Input, Sequential
# from tensorflow.keras.
import numpy as np

# X_train dataset with 10 features and 5000 examples
X = np.random.uniform(low=-1, high=1, size=(4, 5000)).T

# Y dataset with 2 classes and 5000 examples
Y = np.random.randint(0, 1, size=(1, 5000)).T
print(X)
print(X.shape)
print(Y)
print(Y.shape)

# define the input 0th layer
# returns a None x n matrix, where in None is actually 
# an arbitrary value m which will be determined at runtime
inputs = Input(shape=(4,))
inputs

# layer_1 will have m x 5 dimensionality because of 5 nodes 
# in this layer, but will be None x 5 at runtime
layer_1 = Dense(units=5, activation='relu')
A1 = layer_1(inputs)
A1

# layer_2 will have m x 3 dimensionality because of 3 nodes 
# in this layer, but will be None x 3 at runtime
layer_2 = Dense(units=3, activation='relu')
A2 = layer_2(A1)
A2

# layer_3 will have m x 1 dimensionality because of 3 nodes 
# in this layer, but will be None x 3 at runtime
# output = Dense(units=3, activation='softmax')
outputs = Dense(units=1, activation='sigmoid')
A3 = outputs(A2)
A3

# one can say that the above is merely the defining or 
# the phase of mapping out and drawing the architecture 
# of the network. The next phase will now be building such
# an architecture
model = Model(inputs=inputs, outputs=A3, name='4-5-3-1-NN-architecture')
model.compile(optimizer='Adam', loss='mse')

# final phase is feeding input and output data to the compiled/built model
model.fit(X, Y, epochs=50)
model.summary()


# unregularized model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=25, activation="relu"),
    tf.keras.layers.Dense(units=15, activation="relu"),
    tf.keras.layers.Dense(units=1, activation="sigmoid"),
], name='25-15-1-NN_architecture')

model.compile(optimizer='Adam', loss='binary_cross_entropy')

# regularized model

# if you're question before was why regularize each layer when we only regularize the cost function once
# it is because if you recall we have different derivatives of the cost function in each layer and have different
# therefore coefficient matrices in each layer that's why we can manipulate what lambda is for each layer
# and not just for all layers
model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=25, activation="relu", kernel_regularizer=L2(0.01)),
    tf.keras.layers.Dense(units=15, activation="relu", kernel_regularizer=L2(0.01)),
    tf.keras.layers.Dense(units=1, activation="sigmoid", kernel_regularizer=L2(0.01)),
], name='25-15-1-NN_architecture')
